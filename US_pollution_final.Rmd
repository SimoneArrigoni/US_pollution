---
title: "20236 Time Series Analysis - Alaska Pollution Dataset"
author:
- Simone Arrigoni (1794692)
- Luca Badolato (3086040)
- Simone Valle (3088281)
subtitle: "Bocconi University"
date: April, 2020
output: 
  pdf_document
header-includes:
  \usepackage[utf8]{inputenc}
  \usepackage{setspace}
  \usepackage{algpseudocode}
  \usepackage{algorithm}
  \usepackage{bm}
  \usepackage{amsmath}
  \usepackage{amssymb}
  \usepackage{graphicx}
  \usepackage{subfig}
  \usepackage{booktabs, caption}
  \usepackage{array}
  \usepackage{threeparttable}
  \usepackage{listings}
  \usepackage{physics}
  \usepackage{float}
  \floatplacement{figure}{H}
  \usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
  \definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
  \definecolor{mylilas}{RGB}{170,55,241}
  \DeclareMathOperator*{\E}{\mathbb{E}}
  \DeclareMathOperator*{\Ec}{\mathbb{E}_t}
---

```{r, include=FALSE}

# Load useful packages
library(utf8)
library(labeling)
library(rmarkdown)
library(httr)
library(knitr)
library(tseries)
library(scales)
library(dlm)
library(depmixS4)
library(tidyr)
library(tidyverse)
library(ggthemes)
library(magrittr)
library(latex2exp)
library(kableExtra)
library(ggpubr)
library(reshape2)

# Settings
knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE,
                      echo    = FALSE,
                      include = TRUE,
                      fig.pos = "H",
                      fig.align = "center")
```


We obtain the raw dataset from the website \textit{Kaggle} (https://www.kaggle.com/sogun3/uspollution).
It collects data for U.S. states about four main pollutants - Nitrogen Dioxide (\textit{NO2}), Sulphur Dioxide (\textit{SO2}), Carbon Monoxide (\textit{CO}) and Ozone (\textit{O3}) - for every day from 2000 to 2016 with four intraday observations. Importantly, this is an unbalanced panel since the sample periods differs among states.

```{r echo=FALSE}
# Import the dataset for all US states
raw_data <- read.csv("pollution_us_2000_2016.csv", sep = ",", header=T)
```

Given the relatively high frequency of the data and the high dimension of the dataset, we need to shrink it so as to extract more concise information which will allow us to perform our analysis.
For this reason we first aggregate data about pollutants for each state with weekly frequency.

```{r echo=FALSE}
# Preliminary analysis

# partition the dataset to get data for all states
state_label<-unique(raw_data$State)
state_id<-length(state_label)
plotList <- list()

for (idx in 1:state_id){
  subsample <- raw_data[raw_data$State==state_label[idx],]  

  # Weekly CO, NO2, O3, SO2 in mean  for Utah

  counter_w<-nrow(subsample)/28 %>% as.integer()
  
  weekly_CO_mean<-matrix(0,counter_w,1)
  weekly_O3_mean <-matrix(0,counter_w,1)
  weekly_NO2_mean<-matrix(0,counter_w,1)
  weekly_SO2_mean<-matrix(0,counter_w,1)

  for (k in 1:counter_w) {
    i=28*k
    j=k+(27*(k-1))
    weekly_CO_mean[k]<-mean(subsample$CO.Mean[i:j])
    weekly_O3_mean[k]<-mean(subsample$NO2.Mean[i:j]) 
    weekly_NO2_mean[k]<-mean(subsample$O3.Mean[i:j])
    weekly_SO2_mean[k]<-mean(subsample$SO2.Mean[i:j])
  }
  
  #create a matrix for each state with the 4 variables
  nam<-paste("variable_",state_label[idx],sep="")
  assign(nam, data.frame(weekly_CO_mean,weekly_NO2_mean,weekly_O3_mean, weekly_SO2_mean))
  
}

```

```{r echo=FALSE}
# Attach a id number to each State
identifier<-data.frame(1:state_id, state_label)

# Remove mute variable from the local environmet
rm(i)
rm(idx)
rm(j)
rm(k)
rm(nam)
rm(weekly_CO_mean)
rm(weekly_NO2_mean)
rm(weekly_O3_mean)
rm(weekly_SO2_mean)

```

After a closer inspection to the aggregated data, we identified the series for Alaskas's pollutants as the one of main interest. Therefore, we procede providing a plot of such a time series.
The original series spans from 2014-07-01 to 2015-12-31	 
```{r}
# Time series plot (Weekly)
n_weeks<-1:nrow(variable_Alaska)
  W1<-ggplot(variable_Alaska, aes(x=n_weeks, y=weekly_CO_mean))+geom_line()+ggtitle("Alaska")+theme_classic2()
  W2<-ggplot(variable_Alaska, aes(x=n_weeks, y=weekly_NO2_mean))+geom_line()+ggtitle("Alaska")+theme_classic2()
  W3<-ggplot(variable_Alaska, aes(x=n_weeks, y=weekly_O3_mean))+geom_line()+ggtitle("Alaska")+theme_classic2()
  W4<-ggplot(variable_Alaska, aes(x=n_weeks, y=weekly_SO2_mean))+geom_line()+ggtitle("Alaska")+theme_classic2()
  
  Alaska_TSplot_W<-ggarrange(W1, W2, W3, W4, ncol = 2, nrow = 2)
  Alaska_TSplot_W
  
```

The chart shows a rather smooth time series, especially if compared with the other staes. This is justified by the relative low number of observations. Therefore, we aggregate data at a daily frequency and plot them as done before to have an immediate glance of the matter.

```{r echo=FALSE}
# partition the dataset to get data for layer Alaska
alaska_data_D <- raw_data[raw_data$State=="Alaska",]

# daily CO, NO2, O3, SO2 in mean  for Arizona

counter_d<-nrow(alaska_data_D)/4

daily_CO_mean<-matrix(0,counter_d,1)
daily_O3_mean <-matrix(0,counter_d,1)
daily_NO2_mean<-matrix(0,counter_d,1)
daily_SO2_mean<-matrix(0,counter_d,1)

for (k in 1:counter_d) {
    i=4*k
    j=k+(3*(k-1))
    daily_CO_mean[k]<-mean(alaska_data_D$CO.Mean[i:j])
    daily_NO2_mean[k]<-mean(alaska_data_D$NO2.Mean[i:j])
    daily_O3_mean[k]<-mean(alaska_data_D$O3.Mean[i:j])
    daily_SO2_mean[k]<-mean(alaska_data_D$SO2.Mean[i:j])
}

#create a matrix for each state with the 4 variables
assign("daily_variable_Alaska", data.frame(daily_CO_mean,daily_NO2_mean,daily_O3_mean, daily_SO2_mean))

# Remove mute variable ffrom local environment
rm(i)
rm(j)
rm(k)
rm(daily_NO2_mean)
rm(daily_O3_mean)
rm(daily_CO_mean)
rm(daily_SO2_mean)
  

# Time series plot (daily)
n_days<-1:counter_d

D1<-ggplot(data.frame(n_days,daily_variable_Alaska), aes(x=n_days, y=daily_CO_mean))+geom_line()+theme_classic2()
D2<-ggplot(data.frame(n_days, daily_variable_Alaska), aes(x=n_days, y=daily_NO2_mean))+geom_line()+theme_classic2()
D3<-ggplot(data.frame(n_days, daily_variable_Alaska), aes(x=n_days, y=daily_O3_mean))+geom_line()+theme_classic2()
D4<-ggplot(data.frame(n_days, daily_variable_Alaska), aes(x=n_days, y=daily_SO2_mean))+geom_line()+theme_classic2()

Alaska_TSplot_D<-ggarrange(D1, D2, D3, D4, ncol = 2, nrow = 2)
Alaska_TSplot_D

```

We conclude this preliminary step by crating a new dataset storing data for Alaska's pollutants with both daily and weekly frequency which will provide a basis for the core analysis of the project.

```{r}
# export the new dataset to CSV
dif=nrow(daily_variable_Alaska)-nrow(variable_Alaska)
na_cell<-matrix(NA,dif,4)
colnames(na_cell)=colnames(variable_Alaska)
weekly_variable_Alaska<-rbind(variable_Alaska,na_cell)
alaska_data_new<-data.frame(daily_variable_Alaska, weekly_variable_Alaska)

rm(dif)

path_out = getwd()
write.csv(alaska_data_new,paste(path_out,'/Alaska_dataset.csv',sep = ''),row.names=FALSE)

```

The dataset is then made available in a public repository on GitHub (https://raw.githubusercontent.com/SimoneArrigoni/US_pollution/master//Alaska_dataset.csv)



